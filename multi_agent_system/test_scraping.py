#!/usr/bin/env python3
"""
Test script for scraping tools
"""

from tools.scraping_tools import fetch_html_content, extract_clean_text, WebScrapingTool
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

def test_fetch_html_content():
    """Test fetch_html_content function"""
    print('üîç –¢–µ—Å—Ç–∏—Ä—É—é fetch_html_content...')
    try:
        html = fetch_html_content('https://httpbin.org/html', timeout=10)
        print(f'‚úÖ HTML –ø–æ–ª—É—á–µ–Ω: {len(html)} —Å–∏–º–≤–æ–ª–æ–≤')
        return html
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞: {e}')
        return None

def test_extract_clean_text(html=None):
    """Test extract_clean_text function"""
    print('\nüßπ –¢–µ—Å—Ç–∏—Ä—É—é extract_clean_text...')
    try:
        test_html = html[:1000] if html else '<html><body><h1>Test</h1><p>Sample text</p></body></html>'
        clean_text = extract_clean_text(test_html)
        print(f'‚úÖ –ß–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç: {len(clean_text)} —Å–∏–º–≤–æ–ª–æ–≤')
        print(f'–ü—Ä–µ–≤—å—é: {clean_text[:100]}...')
        return clean_text
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞: {e}')
        return None

def test_web_scraping_tool():
    """Test WebScrapingTool class"""
    print('\nüõ†Ô∏è –¢–µ—Å—Ç–∏—Ä—É—é WebScrapingTool...')
    try:
        scraper = WebScrapingTool(timeout=10)
        data = scraper.scrape_website('https://httpbin.org/html')
        print(f'‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–ª—É—á–µ–Ω—ã: {len(data)} –ø–æ–ª–µ–π')
        print(f'–ó–∞–≥–æ–ª–æ–≤–æ–∫: {data.get("title", "N/A")}')
        print(f'–ö–æ–Ω—Ç–µ–Ω—Ç: {len(data.get("content", ""))} —Å–∏–º–≤–æ–ª–æ–≤')
        print(f'–°—Å—ã–ª–∫–∏: {len(data.get("links", []))}')
        print(f'–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {len(data.get("images", []))}')
        return data
    except Exception as e:
        print(f'‚ùå –û—à–∏–±–∫–∞: {e}')
        return None

def test_error_handling():
    """Test error handling"""
    print('\nüö® –¢–µ—Å—Ç–∏—Ä—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫...')
    
    # Test invalid URL
    try:
        fetch_html_content('invalid-url')
        print('‚ùå –î–æ–ª–∂–Ω–∞ –±—ã–ª–∞ –±—ã—Ç—å –æ—à–∏–±–∫–∞ –¥–ª—è –Ω–µ–≤–µ—Ä–Ω–æ–≥–æ URL')
    except Exception as e:
        print(f'‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –æ—à–∏–±–∫–∞: {type(e).__name__}')
    
    # Test timeout
    try:
        fetch_html_content('https://httpbin.org/delay/5', timeout=1)
        print('‚ùå –î–æ–ª–∂–Ω–∞ –±—ã–ª–∞ –±—ã—Ç—å –æ—à–∏–±–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞')
    except Exception as e:
        print(f'‚úÖ –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –æ—à–∏–±–∫–∞ —Ç–∞–π–º–∞—É—Ç–∞: {type(e).__name__}')

if __name__ == '__main__':
    print('üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –º–æ–¥—É–ª—è scraping_tools\n')
    
    # Run tests
    html = test_fetch_html_content()
    clean_text = test_extract_clean_text(html)
    data = test_web_scraping_tool()
    test_error_handling()
    
    print('\n‚úÖ –í—Å–µ —Ç–µ—Å—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω—ã!')

